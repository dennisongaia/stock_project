{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "This week I:\n",
    "- Altered the scaling on my get_data function so that each value has it's own individual scaler, rather than just using one MinMaxScaler object. I then added these scalers to the output dictionary so that I could unscale them later.\n",
    "- Added a function to create a LSTM model.\n",
    "- Added a function to predcit the future price based on the number of days in advance that I wanted to predict (in this case 7 days).\n",
    "- Added a function to create a finished dataframe with the features from the original dataframe, as well as the predicted adjusted close values, and the actual adjusted close values. \n",
    "- Added a function to create a graph of the days vs. price (both the actual adjusted close, and predicted adjusted close)\n",
    "- I then utilised these function on a few different tickers, outputing the predicted price, graph of the dates vs. price, loss, and mean absolute error for each one. Based on these outputted values, I made my buy/sell decisions for this week.   \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An error occured in my code when I tried to run it again today, which did not occur in earlier runs. The result of my erlier runs were as follows: \n",
    "\n",
    "For AMZN:\n",
    "Future price after 7 days is 3525.85$\n",
    "Loss: 0.00044708841596730053\n",
    "Mean absolute error: 82.99083449228097\n",
    "![AMZN Graph](amazon.png)\n",
    "\n",
    "For AAPL:\n",
    "Future price after 7 days is 142.79$\n",
    "Loss: 0.0009056889684870839\n",
    "Mean absolute error: 4.301958548367483\n",
    "![AAPL Graph](apple.png)\n",
    "\n",
    "For BLK:\n",
    "Future price after 7 days is 917.52$\n",
    "Loss: 0.0003547408850863576\n",
    "Mean absolute error: 27.431870308970947\n",
    "![BLK Graph](BLK.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yahoo_fin in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.8.9.1)\n",
      "Requirement already satisfied: feedparser in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from yahoo_fin) (6.0.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from yahoo_fin) (1.3.4)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from yahoo_fin) (2.26.0)\n",
      "Requirement already satisfied: requests-html in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from yahoo_fin) (0.10.0)\n",
      "Requirement already satisfied: sgmllib3k in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from feedparser->yahoo_fin) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas->yahoo_fin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas->yahoo_fin) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas->yahoo_fin) (1.21.4)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->yahoo_fin) (2.0.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->yahoo_fin) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->yahoo_fin) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests->yahoo_fin) (3.3)\n",
      "Requirement already satisfied: parse in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (1.19.0)\n",
      "Requirement already satisfied: pyppeteer>=0.0.14 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (0.2.6)\n",
      "Requirement already satisfied: pyquery in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (1.4.3)\n",
      "Requirement already satisfied: bs4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (0.0.1)\n",
      "Requirement already satisfied: fake-useragent in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (0.1.11)\n",
      "Requirement already satisfied: w3lib in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-html->yahoo_fin) (1.22.0)\n",
      "Requirement already satisfied: websockets<10.0,>=9.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (9.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (4.8.2)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (1.4.4)\n",
      "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyppeteer>=0.0.14->requests-html->yahoo_fin) (8.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->yahoo_fin) (1.15.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from bs4->requests-html->yahoo_fin) (4.10.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyquery->requests-html->yahoo_fin) (1.1.0)\n",
      "Requirement already satisfied: lxml>=2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyquery->requests-html->yahoo_fin) (4.6.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html->yahoo_fin) (3.6.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from beautifulsoup4->bs4->requests-html->yahoo_fin) (2.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install yahoo_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.3.4)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (1.21.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin import stock_info as si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AACG',\n",
       " 'AACI',\n",
       " 'AACIU',\n",
       " 'AACIW',\n",
       " 'AADI',\n",
       " 'AADR',\n",
       " 'AAL',\n",
       " 'AAME',\n",
       " 'AAOI',\n",
       " 'AAON',\n",
       " 'AAPL',\n",
       " 'AATC',\n",
       " 'AAWW',\n",
       " 'AAXJ',\n",
       " 'ABCB',\n",
       " 'ABCL',\n",
       " 'ABCM',\n",
       " 'ABEO',\n",
       " 'ABGI',\n",
       " 'ABIO',\n",
       " 'ABMD',\n",
       " 'ABNB',\n",
       " 'ABOS',\n",
       " 'ABSI',\n",
       " 'ABST',\n",
       " 'ABTX',\n",
       " 'ABUS',\n",
       " 'ABVC',\n",
       " 'ACAD',\n",
       " 'ACAH',\n",
       " 'ACAHU',\n",
       " 'ACAHW',\n",
       " 'ACB',\n",
       " 'ACBA',\n",
       " 'ACBAU',\n",
       " 'ACBAW',\n",
       " 'ACBI',\n",
       " 'ACCD',\n",
       " 'ACER',\n",
       " 'ACET',\n",
       " 'ACEV',\n",
       " 'ACEVU',\n",
       " 'ACEVW',\n",
       " 'ACGL',\n",
       " 'ACGLN',\n",
       " 'ACGLO',\n",
       " 'ACHC',\n",
       " 'ACHL',\n",
       " 'ACHV',\n",
       " 'ACIU',\n",
       " 'ACIW',\n",
       " 'ACKIT',\n",
       " 'ACKIU',\n",
       " 'ACKIW',\n",
       " 'ACLS',\n",
       " 'ACMR',\n",
       " 'ACNB',\n",
       " 'ACOR',\n",
       " 'ACQR',\n",
       " 'ACQRU',\n",
       " 'ACQRW',\n",
       " 'ACRS',\n",
       " 'ACRX',\n",
       " 'ACST',\n",
       " 'ACT',\n",
       " 'ACTD',\n",
       " 'ACTDU',\n",
       " 'ACTDW',\n",
       " 'ACTG',\n",
       " 'ACVA',\n",
       " 'ACWI',\n",
       " 'ACWX',\n",
       " 'ACXP',\n",
       " 'ADAG',\n",
       " 'ADALU',\n",
       " 'ADAP',\n",
       " 'ADBE',\n",
       " 'ADER',\n",
       " 'ADERU',\n",
       " 'ADERW',\n",
       " 'ADES',\n",
       " 'ADGI',\n",
       " 'ADI',\n",
       " 'ADIL',\n",
       " 'ADILW',\n",
       " 'ADMA',\n",
       " 'ADMP',\n",
       " 'ADN',\n",
       " 'ADNWW',\n",
       " 'ADOC',\n",
       " 'ADOCR',\n",
       " 'ADOCW',\n",
       " 'ADP',\n",
       " 'ADPT',\n",
       " 'ADRE',\n",
       " 'ADSK',\n",
       " 'ADTN',\n",
       " 'ADTX',\n",
       " 'ADUS',\n",
       " 'ADV',\n",
       " 'ADVM',\n",
       " 'ADVWW',\n",
       " 'ADXN',\n",
       " 'ADXS',\n",
       " 'AEAC',\n",
       " 'AEACU',\n",
       " 'AEACW',\n",
       " 'AEAEU',\n",
       " 'AEHA',\n",
       " 'AEHAU',\n",
       " 'AEHAW',\n",
       " 'AEHL',\n",
       " 'AEHR',\n",
       " 'AEI',\n",
       " 'AEIS',\n",
       " 'AEMD',\n",
       " 'AEP',\n",
       " 'AEPPL',\n",
       " 'AEPPZ',\n",
       " 'AERC',\n",
       " 'AERI',\n",
       " 'AESE',\n",
       " 'AEY',\n",
       " 'AEYE',\n",
       " 'AEZS',\n",
       " 'AFACU',\n",
       " 'AFAQ',\n",
       " 'AFAQU',\n",
       " 'AFAQW',\n",
       " 'AFBI',\n",
       " 'AFCG',\n",
       " 'AFIB',\n",
       " 'AFIN',\n",
       " 'AFINO',\n",
       " 'AFINP',\n",
       " 'AFMD',\n",
       " 'AFRM',\n",
       " 'AFYA',\n",
       " 'AGBA',\n",
       " 'AGBAR',\n",
       " 'AGBAU',\n",
       " 'AGBAW',\n",
       " 'AGC',\n",
       " 'AGCUU',\n",
       " 'AGCWW',\n",
       " 'AGEN',\n",
       " 'AGFS',\n",
       " 'AGFY',\n",
       " 'AGGR',\n",
       " 'AGGRU',\n",
       " 'AGGRW',\n",
       " 'AGIL',\n",
       " 'AGILW',\n",
       " 'AGIO',\n",
       " 'AGLE',\n",
       " 'AGMH',\n",
       " 'AGNC',\n",
       " 'AGNCM',\n",
       " 'AGNCN',\n",
       " 'AGNCO',\n",
       " 'AGNCP',\n",
       " 'AGNG',\n",
       " 'AGRI',\n",
       " 'AGRIW',\n",
       " 'AGRX',\n",
       " 'AGTC',\n",
       " 'AGYS',\n",
       " 'AGZD',\n",
       " 'AHCO',\n",
       " 'AHI',\n",
       " 'AHPA',\n",
       " 'AHPAU',\n",
       " 'AHPAW',\n",
       " 'AHPI',\n",
       " 'AIA',\n",
       " 'AIH',\n",
       " 'AIHS',\n",
       " 'AIKI',\n",
       " 'AIMC',\n",
       " 'AINV',\n",
       " 'AIP',\n",
       " 'AIQ',\n",
       " 'AIRG',\n",
       " 'AIRR',\n",
       " 'AIRS',\n",
       " 'AIRT',\n",
       " 'AIRTP',\n",
       " 'AKAM',\n",
       " 'AKBA',\n",
       " 'AKIC',\n",
       " 'AKICU',\n",
       " 'AKICW',\n",
       " 'AKRO',\n",
       " 'AKTS',\n",
       " 'AKTX',\n",
       " 'AKU',\n",
       " 'AKUS',\n",
       " 'AKYA',\n",
       " 'ALAC',\n",
       " 'ALACR',\n",
       " 'ALACU',\n",
       " 'ALACW',\n",
       " 'ALBO',\n",
       " 'ALCO',\n",
       " 'ALDX',\n",
       " 'ALEC',\n",
       " 'ALF',\n",
       " 'ALFIW',\n",
       " 'ALGM',\n",
       " 'ALGN',\n",
       " 'ALGS',\n",
       " 'ALGT',\n",
       " 'ALHC',\n",
       " 'ALIM',\n",
       " 'ALJJ',\n",
       " 'ALKS',\n",
       " 'ALKT',\n",
       " 'ALLK',\n",
       " 'ALLO',\n",
       " 'ALLT',\n",
       " 'ALNA',\n",
       " 'ALNY',\n",
       " 'ALORU',\n",
       " 'ALOT',\n",
       " 'ALPA',\n",
       " 'ALPAU',\n",
       " 'ALPAW',\n",
       " 'ALPN',\n",
       " 'ALPP',\n",
       " 'ALRM',\n",
       " 'ALRN',\n",
       " 'ALRS',\n",
       " 'ALT',\n",
       " 'ALTM',\n",
       " 'ALTO',\n",
       " 'ALTR',\n",
       " 'ALTU',\n",
       " 'ALTUU',\n",
       " 'ALTUW',\n",
       " 'ALTY',\n",
       " 'ALVR',\n",
       " 'ALXO',\n",
       " 'ALYA',\n",
       " 'ALZN',\n",
       " 'AMAL',\n",
       " 'AMAO',\n",
       " 'AMAOU',\n",
       " 'AMAOW',\n",
       " 'AMAT',\n",
       " 'AMBA',\n",
       " 'AMCI',\n",
       " 'AMCIU',\n",
       " 'AMCIW',\n",
       " 'AMCX',\n",
       " 'AMD',\n",
       " 'AMED',\n",
       " 'AMEH',\n",
       " 'AMGN',\n",
       " 'AMKR',\n",
       " 'AMNB',\n",
       " 'AMOT',\n",
       " 'AMPG',\n",
       " 'AMPGW',\n",
       " 'AMPH',\n",
       " 'AMPL',\n",
       " 'AMRK',\n",
       " 'AMRN',\n",
       " 'AMRS',\n",
       " 'AMSC',\n",
       " 'AMSF',\n",
       " 'AMST',\n",
       " 'AMSWA',\n",
       " 'AMTB',\n",
       " 'AMTI',\n",
       " 'AMTX',\n",
       " 'AMWD',\n",
       " 'AMYT',\n",
       " 'AMZN',\n",
       " 'ANAB',\n",
       " 'ANAT',\n",
       " 'ANDE',\n",
       " 'ANEB',\n",
       " 'ANGI',\n",
       " 'ANGL',\n",
       " 'ANGN',\n",
       " 'ANGO',\n",
       " 'ANIK',\n",
       " 'ANIP',\n",
       " 'ANIX',\n",
       " 'ANNX',\n",
       " 'ANPC',\n",
       " 'ANSS',\n",
       " 'ANTE',\n",
       " 'ANY',\n",
       " 'ANZU',\n",
       " 'ANZUU',\n",
       " 'ANZUW',\n",
       " 'AOSL',\n",
       " 'AOUT',\n",
       " 'APA',\n",
       " 'APAC',\n",
       " 'APACU',\n",
       " 'APACW',\n",
       " 'APDN',\n",
       " 'APEI',\n",
       " 'APEN',\n",
       " 'API',\n",
       " 'APLS',\n",
       " 'APLT',\n",
       " 'APM',\n",
       " 'APMI',\n",
       " 'APMIU',\n",
       " 'APMIW',\n",
       " 'APOG',\n",
       " 'APP',\n",
       " 'APPF',\n",
       " 'APPH',\n",
       " 'APPHW',\n",
       " 'APPN',\n",
       " 'APPS',\n",
       " 'APR',\n",
       " 'APRE',\n",
       " 'APTM',\n",
       " 'APTMU',\n",
       " 'APTMW',\n",
       " 'APTO',\n",
       " 'APTX',\n",
       " 'APVO',\n",
       " 'APWC',\n",
       " 'APYX',\n",
       " 'AQB',\n",
       " 'AQMS',\n",
       " 'AQST',\n",
       " 'AQWA',\n",
       " 'ARAV',\n",
       " 'ARAY',\n",
       " 'ARBE',\n",
       " 'ARBEW',\n",
       " 'ARBG',\n",
       " 'ARBGU',\n",
       " 'ARBGW',\n",
       " 'ARBK',\n",
       " 'ARBKL',\n",
       " 'ARCB',\n",
       " 'ARCC',\n",
       " 'ARCE',\n",
       " 'ARCKU',\n",
       " 'ARCT',\n",
       " 'ARDS',\n",
       " 'ARDX',\n",
       " 'AREC',\n",
       " 'ARGU',\n",
       " 'ARGUU',\n",
       " 'ARGUW',\n",
       " 'ARGX',\n",
       " 'ARHS',\n",
       " 'ARIZU',\n",
       " 'ARKO',\n",
       " 'ARKOW',\n",
       " 'ARKR',\n",
       " 'ARLP',\n",
       " 'ARNA',\n",
       " 'AROW',\n",
       " 'ARQQ',\n",
       " 'ARQQW',\n",
       " 'ARQT',\n",
       " 'ARRW',\n",
       " 'ARRWU',\n",
       " 'ARRWW',\n",
       " 'ARRY',\n",
       " 'ARTA',\n",
       " 'ARTAU',\n",
       " 'ARTAW',\n",
       " 'ARTE',\n",
       " 'ARTEU',\n",
       " 'ARTEW',\n",
       " 'ARTL',\n",
       " 'ARTLW',\n",
       " 'ARTNA',\n",
       " 'ARTW',\n",
       " 'ARVL',\n",
       " 'ARVN',\n",
       " 'ARWR',\n",
       " 'ARYD',\n",
       " 'ARYE',\n",
       " 'ASAX',\n",
       " 'ASAXU',\n",
       " 'ASAXW',\n",
       " 'ASET',\n",
       " 'ASLE',\n",
       " 'ASLEW',\n",
       " 'ASLN',\n",
       " 'ASMB',\n",
       " 'ASML',\n",
       " 'ASND',\n",
       " 'ASO',\n",
       " 'ASPA',\n",
       " 'ASPAU',\n",
       " 'ASPAW',\n",
       " 'ASPC',\n",
       " 'ASPCU',\n",
       " 'ASPCW',\n",
       " 'ASPS',\n",
       " 'ASPU',\n",
       " 'ASRT',\n",
       " 'ASRV',\n",
       " 'ASTC',\n",
       " 'ASTE',\n",
       " 'ASTL',\n",
       " 'ASTLW',\n",
       " 'ASTR',\n",
       " 'ASTRW',\n",
       " 'ASTS',\n",
       " 'ASTSW',\n",
       " 'ASUR',\n",
       " 'ASYS',\n",
       " 'ATAI',\n",
       " 'ATAX',\n",
       " 'ATCOL',\n",
       " 'ATCX',\n",
       " 'ATEC',\n",
       " 'ATER',\n",
       " 'ATEX',\n",
       " 'ATHA',\n",
       " 'ATHE',\n",
       " 'ATHX',\n",
       " 'ATIF',\n",
       " 'ATLC',\n",
       " 'ATLCL',\n",
       " 'ATLCP',\n",
       " 'ATLO',\n",
       " 'ATNF',\n",
       " 'ATNFW',\n",
       " 'ATNI',\n",
       " 'ATNX',\n",
       " 'ATOM',\n",
       " 'ATOS',\n",
       " 'ATRA',\n",
       " 'ATRC',\n",
       " 'ATRI',\n",
       " 'ATRO',\n",
       " 'ATRS',\n",
       " 'ATSG',\n",
       " 'ATSPT',\n",
       " 'ATSPU',\n",
       " 'ATSPW',\n",
       " 'ATVC',\n",
       " 'ATVCU',\n",
       " 'ATVCW',\n",
       " 'ATVI',\n",
       " 'ATXI',\n",
       " 'ATXS',\n",
       " 'ATY',\n",
       " 'AUB',\n",
       " 'AUBAP',\n",
       " 'AUBN',\n",
       " 'AUDC',\n",
       " 'AUGX',\n",
       " 'AUID',\n",
       " 'AUPH',\n",
       " 'AUR',\n",
       " 'AURA',\n",
       " 'AURC',\n",
       " 'AURCU',\n",
       " 'AURCW',\n",
       " 'AUROW',\n",
       " 'AUTL',\n",
       " 'AUTO',\n",
       " 'AUUD',\n",
       " 'AUUDW',\n",
       " 'AUVI',\n",
       " 'AUVIP',\n",
       " 'AVACU',\n",
       " 'AVAH',\n",
       " 'AVAV',\n",
       " 'AVCO',\n",
       " 'AVCT',\n",
       " 'AVCTW',\n",
       " 'AVDL',\n",
       " 'AVDX',\n",
       " 'AVEO',\n",
       " 'AVGO',\n",
       " 'AVGOP',\n",
       " 'AVGR',\n",
       " 'AVHI',\n",
       " 'AVHIU',\n",
       " 'AVHIW',\n",
       " 'AVID',\n",
       " 'AVIR',\n",
       " 'AVNW',\n",
       " 'AVO',\n",
       " 'AVPT',\n",
       " 'AVPTW',\n",
       " 'AVRO',\n",
       " 'AVT',\n",
       " 'AVTE',\n",
       " 'AVTX',\n",
       " 'AVXL',\n",
       " 'AWH',\n",
       " 'AWRE',\n",
       " 'AXDX',\n",
       " 'AXGN',\n",
       " 'AXLA',\n",
       " 'AXNX',\n",
       " 'AXON',\n",
       " 'AXSM',\n",
       " 'AXTI',\n",
       " 'AY',\n",
       " 'AYLA',\n",
       " 'AYRO',\n",
       " 'AYTU',\n",
       " 'AZN',\n",
       " 'AZPN',\n",
       " 'AZYO',\n",
       " 'BAND',\n",
       " 'BANF',\n",
       " 'BANFP',\n",
       " 'BANR',\n",
       " 'BANX',\n",
       " 'BAOS',\n",
       " 'BASE',\n",
       " 'BATRA',\n",
       " 'BATRK',\n",
       " 'BBBY',\n",
       " 'BBCP',\n",
       " 'BBGI',\n",
       " 'BBH',\n",
       " 'BBI',\n",
       " 'BBIG',\n",
       " 'BBIO',\n",
       " 'BBLG',\n",
       " 'BBLGW',\n",
       " 'BBQ',\n",
       " 'BBSI',\n",
       " 'BCAB',\n",
       " 'BCAC',\n",
       " 'BCACU',\n",
       " 'BCACW',\n",
       " 'BCBP',\n",
       " 'BCDA',\n",
       " 'BCDAW',\n",
       " 'BCEL',\n",
       " 'BCLI',\n",
       " 'BCML',\n",
       " 'BCOR',\n",
       " 'BCOV',\n",
       " 'BCOW',\n",
       " 'BCPC',\n",
       " 'BCRX',\n",
       " 'BCSAU',\n",
       " 'BCTX',\n",
       " 'BCTXW',\n",
       " 'BCYC',\n",
       " 'BDSI',\n",
       " 'BDSX',\n",
       " 'BDTX',\n",
       " 'BEAM',\n",
       " 'BEAT',\n",
       " 'BEATW',\n",
       " 'BECN',\n",
       " 'BEEM',\n",
       " 'BEEMW',\n",
       " 'BELFA',\n",
       " 'BELFB',\n",
       " 'BENE',\n",
       " 'BENER',\n",
       " 'BENEU',\n",
       " 'BENEW',\n",
       " 'BFC',\n",
       " 'BFI',\n",
       " 'BFIIW',\n",
       " 'BFIN',\n",
       " 'BFIT',\n",
       " 'BFRA',\n",
       " 'BFRI',\n",
       " 'BFRIW',\n",
       " 'BFST',\n",
       " 'BGCP',\n",
       " 'BGFV',\n",
       " 'BGNE',\n",
       " 'BGRN',\n",
       " 'BGRY',\n",
       " 'BGRYW',\n",
       " 'BHAC',\n",
       " 'BHACU',\n",
       " 'BHACW',\n",
       " 'BHAT',\n",
       " 'BHF',\n",
       " 'BHFAL',\n",
       " 'BHFAM',\n",
       " 'BHFAN',\n",
       " 'BHFAO',\n",
       " 'BHFAP',\n",
       " 'BHSE',\n",
       " 'BHSEU',\n",
       " 'BHSEW',\n",
       " 'BHTG',\n",
       " 'BIB',\n",
       " 'BICK',\n",
       " 'BIDU',\n",
       " 'BIGC',\n",
       " 'BIIB',\n",
       " 'BILI',\n",
       " 'BIMI',\n",
       " 'BIOC',\n",
       " 'BIOL',\n",
       " 'BIOT',\n",
       " 'BIOTU',\n",
       " 'BIOTW',\n",
       " 'BIOX',\n",
       " 'BIRD',\n",
       " 'BIS',\n",
       " 'BITF',\n",
       " 'BITS',\n",
       " 'BIVI',\n",
       " 'BJDX',\n",
       " 'BJK',\n",
       " 'BJRI',\n",
       " 'BKCC',\n",
       " 'BKCH',\n",
       " 'BKEP',\n",
       " 'BKEPP',\n",
       " 'BKNG',\n",
       " 'BKSC',\n",
       " 'BKYI',\n",
       " 'BL',\n",
       " 'BLBD',\n",
       " 'BLBX',\n",
       " 'BLCM',\n",
       " 'BLCN',\n",
       " 'BLCT',\n",
       " 'BLDE',\n",
       " 'BLDEW',\n",
       " 'BLDP',\n",
       " 'BLEUU',\n",
       " 'BLFS',\n",
       " 'BLFY',\n",
       " 'BLI',\n",
       " 'BLIN',\n",
       " 'BLKB',\n",
       " 'BLMN',\n",
       " 'BLNG',\n",
       " 'BLNGU',\n",
       " 'BLNGW',\n",
       " 'BLNK',\n",
       " 'BLNKW',\n",
       " 'BLPH',\n",
       " 'BLRX',\n",
       " 'BLSA',\n",
       " 'BLTS',\n",
       " 'BLTSU',\n",
       " 'BLTSW',\n",
       " 'BLU',\n",
       " 'BLUE',\n",
       " 'BLZE',\n",
       " 'BMAQ',\n",
       " 'BMAQR',\n",
       " 'BMAQU',\n",
       " 'BMAQW',\n",
       " 'BMBL',\n",
       " 'BMEA',\n",
       " 'BMRA',\n",
       " 'BMRC',\n",
       " 'BMRN',\n",
       " 'BMTC',\n",
       " 'BND',\n",
       " 'BNDW',\n",
       " 'BNDX',\n",
       " 'BNFT',\n",
       " 'BNGO',\n",
       " 'BNGOW',\n",
       " 'BNIX',\n",
       " 'BNIXR',\n",
       " 'BNIXW',\n",
       " 'BNNR',\n",
       " 'BNNRU',\n",
       " 'BNNRW',\n",
       " 'BNR',\n",
       " 'BNSO',\n",
       " 'BNTC',\n",
       " 'BNTX',\n",
       " 'BOKF',\n",
       " 'BOLT',\n",
       " 'BOMN',\n",
       " 'BON',\n",
       " 'BOOM',\n",
       " 'BOSC',\n",
       " 'BOTJ',\n",
       " 'BOTZ',\n",
       " 'BOXL',\n",
       " 'BPMC',\n",
       " 'BPOP',\n",
       " 'BPOPM',\n",
       " 'BPRN',\n",
       " 'BPTH',\n",
       " 'BPTS',\n",
       " 'BPYPM',\n",
       " 'BPYPN',\n",
       " 'BPYPO',\n",
       " 'BPYPP',\n",
       " 'BRAG',\n",
       " 'BRCN',\n",
       " 'BREZ',\n",
       " 'BREZR',\n",
       " 'BREZW',\n",
       " 'BRID',\n",
       " 'BRIV',\n",
       " 'BRIVU',\n",
       " 'BRIVW',\n",
       " 'BRKL',\n",
       " 'BRKR',\n",
       " 'BRKS',\n",
       " 'BRLI',\n",
       " 'BRLIR',\n",
       " 'BRLIU',\n",
       " 'BRLIW',\n",
       " 'BRLT',\n",
       " 'BROG',\n",
       " 'BROGW',\n",
       " 'BRP',\n",
       " 'BRPM',\n",
       " 'BRPMU',\n",
       " 'BRPMW',\n",
       " 'BRQS',\n",
       " 'BRTX',\n",
       " 'BRY',\n",
       " 'BRZE',\n",
       " 'BSAE',\n",
       " 'BSBE',\n",
       " 'BSBK',\n",
       " 'BSCE',\n",
       " 'BSCL',\n",
       " 'BSCM',\n",
       " 'BSCN',\n",
       " 'BSCO',\n",
       " 'BSCP',\n",
       " 'BSCQ',\n",
       " 'BSCR',\n",
       " 'BSCS',\n",
       " 'BSCT',\n",
       " 'BSCU',\n",
       " 'BSCV',\n",
       " 'BSDE',\n",
       " 'BSET',\n",
       " 'BSFC',\n",
       " 'BSGA',\n",
       " 'BSGAR',\n",
       " 'BSGAU',\n",
       " 'BSGM',\n",
       " 'BSJL',\n",
       " 'BSJM',\n",
       " 'BSJN',\n",
       " 'BSJO',\n",
       " 'BSJP',\n",
       " 'BSJQ',\n",
       " 'BSJR',\n",
       " 'BSJS',\n",
       " 'BSJT',\n",
       " 'BSKY',\n",
       " 'BSKYU',\n",
       " 'BSKYW',\n",
       " 'BSML',\n",
       " 'BSMM',\n",
       " 'BSMN',\n",
       " 'BSMO',\n",
       " 'BSMP',\n",
       " 'BSMQ',\n",
       " 'BSMR',\n",
       " 'BSMS',\n",
       " 'BSMT',\n",
       " 'BSMU',\n",
       " 'BSMV',\n",
       " 'BSQR',\n",
       " 'BSRR',\n",
       " 'BSVN',\n",
       " 'BSY',\n",
       " 'BTAI',\n",
       " 'BTAQ',\n",
       " 'BTAQU',\n",
       " 'BTAQW',\n",
       " 'BTB',\n",
       " 'BTBD',\n",
       " 'BTBDW',\n",
       " 'BTBT',\n",
       " 'BTCS',\n",
       " 'BTCY',\n",
       " 'BTEC',\n",
       " 'BTF',\n",
       " 'BTNB',\n",
       " 'BTRS',\n",
       " 'BTRSW',\n",
       " 'BTTX',\n",
       " 'BTWN',\n",
       " 'BTWNU',\n",
       " 'BTWNW',\n",
       " 'BTX',\n",
       " 'BUG',\n",
       " 'BUSE',\n",
       " 'BVS',\n",
       " 'BVXV',\n",
       " 'BWAC',\n",
       " 'BWACU',\n",
       " 'BWACW',\n",
       " 'BWAY',\n",
       " 'BWB',\n",
       " 'BWBBP',\n",
       " 'BWC',\n",
       " 'BWCAU',\n",
       " 'BWCAW',\n",
       " 'BWEN',\n",
       " 'BWFG',\n",
       " 'BWMN',\n",
       " 'BWMX',\n",
       " 'BXRX',\n",
       " 'BYFC',\n",
       " 'BYND',\n",
       " 'BYRN',\n",
       " 'BYSI',\n",
       " 'BYTS',\n",
       " 'BYTSU',\n",
       " 'BYTSW',\n",
       " 'BZ',\n",
       " 'BZUN',\n",
       " 'CAAS',\n",
       " 'CABA',\n",
       " 'CAC',\n",
       " 'CACC',\n",
       " 'CACG',\n",
       " 'CADL',\n",
       " 'CAKE',\n",
       " 'CALA',\n",
       " 'CALB',\n",
       " 'CALM',\n",
       " 'CALT',\n",
       " 'CAMP',\n",
       " 'CAMT',\n",
       " 'CAN',\n",
       " 'CAPR',\n",
       " 'CAR',\n",
       " 'CARA',\n",
       " 'CARE',\n",
       " 'CARG',\n",
       " 'CARV',\n",
       " 'CARZ',\n",
       " 'CASA',\n",
       " 'CASH',\n",
       " 'CASI',\n",
       " 'CASS',\n",
       " 'CASY',\n",
       " 'CATC',\n",
       " 'CATH',\n",
       " 'CATY',\n",
       " 'CBAN',\n",
       " 'CBAT',\n",
       " 'CBAY',\n",
       " 'CBFV',\n",
       " 'CBIO',\n",
       " 'CBNK',\n",
       " 'CBRGU',\n",
       " 'CBRL',\n",
       " 'CBSH',\n",
       " 'CBTX',\n",
       " 'CCAI',\n",
       " 'CCAIU',\n",
       " 'CCAIW',\n",
       " 'CCAP',\n",
       " 'CCB',\n",
       " 'CCBG',\n",
       " 'CCCC',\n",
       " 'CCD',\n",
       " 'CCEL',\n",
       " 'CCEP',\n",
       " 'CCLP',\n",
       " 'CCMP',\n",
       " 'CCNC',\n",
       " 'CCNE',\n",
       " 'CCNEP',\n",
       " 'CCOI',\n",
       " 'CCRN',\n",
       " 'CCSI',\n",
       " 'CCTSU',\n",
       " 'CCXI',\n",
       " 'CD',\n",
       " 'CDAK',\n",
       " 'CDAQU',\n",
       " 'CDC',\n",
       " 'CDEV',\n",
       " 'CDK',\n",
       " 'CDL',\n",
       " 'CDLX',\n",
       " 'CDMO',\n",
       " 'CDNA',\n",
       " 'CDNS',\n",
       " 'CDTX',\n",
       " 'CDW',\n",
       " 'CDXC',\n",
       " 'CDXS',\n",
       " 'CDZI',\n",
       " 'CDZIP',\n",
       " 'CECE',\n",
       " 'CEFA',\n",
       " 'CELC',\n",
       " 'CELH',\n",
       " 'CELU',\n",
       " 'CELUW',\n",
       " 'CEMI',\n",
       " 'CENQ',\n",
       " 'CENQU',\n",
       " 'CENQW',\n",
       " 'CENT',\n",
       " 'CENTA',\n",
       " 'CENX',\n",
       " 'CERE',\n",
       " 'CERN',\n",
       " 'CERS',\n",
       " 'CERT',\n",
       " 'CETX',\n",
       " 'CETXP',\n",
       " 'CETXW',\n",
       " 'CEVA',\n",
       " 'CEY',\n",
       " 'CFA',\n",
       " 'CFB',\n",
       " 'CFBK',\n",
       " 'CFFE',\n",
       " 'CFFEU',\n",
       " 'CFFEW',\n",
       " 'CFFI',\n",
       " 'CFFN',\n",
       " 'CFFVU',\n",
       " 'CFFVW',\n",
       " 'CFIV',\n",
       " 'CFIVU',\n",
       " 'CFIVW',\n",
       " 'CFLT',\n",
       " 'CFMS',\n",
       " 'CFO',\n",
       " 'CFRX',\n",
       " 'CFV',\n",
       " 'CFVI',\n",
       " 'CFVIU',\n",
       " 'CFVIW',\n",
       " 'CG',\n",
       " 'CGABL',\n",
       " 'CGBD',\n",
       " 'CGC',\n",
       " 'CGEM',\n",
       " 'CGEN',\n",
       " 'CGNT',\n",
       " 'CGNX',\n",
       " 'CGO',\n",
       " 'CGRN',\n",
       " 'CGTX',\n",
       " 'CHB',\n",
       " 'CHCI',\n",
       " 'CHCO',\n",
       " 'CHDN',\n",
       " 'CHEF',\n",
       " 'CHEK',\n",
       " 'CHEKZ',\n",
       " 'CHI',\n",
       " 'CHK',\n",
       " 'CHKEL',\n",
       " 'CHKEW',\n",
       " 'CHKEZ',\n",
       " 'CHKP',\n",
       " 'CHMG',\n",
       " 'CHNA',\n",
       " 'CHNG',\n",
       " 'CHNGU',\n",
       " 'CHNR',\n",
       " 'CHPM',\n",
       " 'CHPMU',\n",
       " 'CHPMW',\n",
       " 'CHRS',\n",
       " 'CHRW',\n",
       " 'CHSCL',\n",
       " 'CHSCM',\n",
       " 'CHSCN',\n",
       " 'CHSCO',\n",
       " 'CHSCP',\n",
       " 'CHTR',\n",
       " 'CHUY',\n",
       " 'CHW',\n",
       " 'CHWA',\n",
       " 'CHWAU',\n",
       " 'CHWAW',\n",
       " 'CHX',\n",
       " 'CHY',\n",
       " 'CIBR',\n",
       " 'CID',\n",
       " 'CIDM',\n",
       " 'CIFR',\n",
       " 'CIFRW',\n",
       " 'CIGI',\n",
       " 'CIH',\n",
       " 'CIIG',\n",
       " 'CIIGU',\n",
       " 'CIIGW',\n",
       " 'CIL',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si.tickers_nasdaq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.21.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['adjclose', 'volume', 'open', 'high', 'low']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.21.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (4.0.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.13.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (47.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ticker, window=50, predict=1):\n",
    "    df = si.get_data(ticker)\n",
    "    output = {}\n",
    "    output['original df'] = df.copy()\n",
    "\n",
    "    for col in features: \n",
    "        if col not in features:\n",
    "            return f'Missing {col}'\n",
    "    \n",
    "    if 'date' not in df.columns:\n",
    "        df['date'] = df.index\n",
    "\n",
    "    scalers = {}\n",
    "    for feature in features:\n",
    "        scaler = MinMaxScaler()\n",
    "        df[feature] = scaler.fit_transform(np.expand_dims(df[feature].values, axis=1))\n",
    "        scalers[feature] = scaler\n",
    "    output['scalers'] = scalers\n",
    "    \n",
    "    df['predicted'] = df['adjclose'].shift(-predict)\n",
    "    last_values = np.array(df[features].tail(predict)) \n",
    "    df.dropna(inplace=True)\n",
    " \n",
    "    predicted_val = df['predicted'].values\n",
    "    features_dates = df[features + ['date']].values\n",
    "    d = deque(maxlen=window)\n",
    "    window_seq = []\n",
    "\n",
    "    for i in range(len(features_dates)):\n",
    "        d.append(features_dates[i])\n",
    "        if len(d) == window:\n",
    "            window_seq.append([np.array(d), predicted_val[i]])\n",
    "    \n",
    "    # final feature values left after broken up into window sequences, and last values \n",
    "    # len(last_values) = (window + predict)\n",
    "    last_values = list([seq[:len(features)] for seq in d]) + list(last_values) \n",
    "    last_values = np.array(last_values).astype(np.float32)\n",
    "    output['last values'] = last_values\n",
    "\n",
    "    x, y = [], []\n",
    "    for X, Y in window_seq:\n",
    "        x.append(X)\n",
    "        y.append(Y)\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "\n",
    "    output['x train'], output['x test'], output['y train'], output['y test'] = train_test_split(x, y, test_size=.2)\n",
    "\n",
    "    dates = output['x test'][:, -1, -1]\n",
    "    output['test df'] = output['original df'].loc[dates]\n",
    "    # print(type(output['test df']))\n",
    "    output['test df'] = output['test df'][~output['test df'].index.duplicated()]\n",
    "    output['x train'] = output['x train'][:, :, : len(features)].astype(np.float32)\n",
    "    output['x test'] = output['x test'][:, :, : len(features)].astype(np.float32)\n",
    "\n",
    "    print(type(output['test df']))\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'original df':                   open        high         low       close    adjclose  \\\n",
       " 1980-12-12    0.128348    0.128906    0.128348    0.128348    0.100453   \n",
       " 1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095213   \n",
       " 1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088224   \n",
       " 1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090408   \n",
       " 1980-12-18    0.118862    0.119420    0.118862    0.118862    0.093029   \n",
       " ...                ...         ...         ...         ...         ...   \n",
       " 2021-11-29  159.369995  161.190002  158.789993  160.240005  160.240005   \n",
       " 2021-11-30  159.990005  165.520004  159.919998  165.300003  165.300003   \n",
       " 2021-12-01  167.479996  170.300003  164.529999  164.770004  164.770004   \n",
       " 2021-12-02  158.740005  164.199997  157.800003  163.759995  163.759995   \n",
       " 2021-12-03  164.020004  164.960007  159.720001  161.839996  161.839996   \n",
       " \n",
       "                volume ticker  \n",
       " 1980-12-12  469033600   AAPL  \n",
       " 1980-12-15  175884800   AAPL  \n",
       " 1980-12-16  105728000   AAPL  \n",
       " 1980-12-17   86441600   AAPL  \n",
       " 1980-12-18   73449600   AAPL  \n",
       " ...               ...    ...  \n",
       " 2021-11-29   88748200   AAPL  \n",
       " 2021-11-30  174048100   AAPL  \n",
       " 2021-12-01  152052500   AAPL  \n",
       " 2021-12-02  136739200   AAPL  \n",
       " 2021-12-03  117938300   AAPL  \n",
       " \n",
       " [10333 rows x 7 columns],\n",
       " 'scalers': {'adjclose': MinMaxScaler(),\n",
       "  'volume': MinMaxScaler(),\n",
       "  'open': MinMaxScaler(),\n",
       "  'high': MinMaxScaler(),\n",
       "  'low': MinMaxScaler()},\n",
       " 'last values': array([[0.886943  , 0.00873637, 0.87559   , 0.8636126 , 0.88515383],\n",
       "        [0.88748676, 0.00720567, 0.8696772 , 0.8659033 , 0.88466746],\n",
       "        [0.8781213 , 0.00999115, 0.8685424 , 0.8570341 , 0.87408876],\n",
       "        [0.85721534, 0.01468305, 0.85528314, 0.8499268 , 0.8611389 ],\n",
       "        [0.86277425, 0.01005196, 0.85062444, 0.84816474, 0.86320597],\n",
       "        [0.8547381 , 0.01198309, 0.85773194, 0.84775364, 0.8586462 ],\n",
       "        [0.8616866 , 0.01275184, 0.84722   , 0.83917797, 0.8454532 ],\n",
       "        [0.8404785 , 0.01324801, 0.84638387, 0.83500767, 0.8403462 ],\n",
       "        [0.85238165, 0.01089531, 0.832826  , 0.8351839 , 0.8469731 ],\n",
       "        [0.8577592 , 0.0112133 , 0.8327066 , 0.83465517, 0.8409541 ],\n",
       "        [0.86555356, 0.00831793, 0.8541483 , 0.8468138 , 0.867401  ],\n",
       "        [0.8631971 , 0.00791182, 0.8599418 , 0.8465788 , 0.86642826],\n",
       "        [0.8626534 , 0.00868436, 0.84942997, 0.8502793 , 0.86186844],\n",
       "        [0.8547985 , 0.00984094, 0.85516363, 0.8411163 , 0.85718703],\n",
       "        [0.85117316, 0.01061257, 0.84327817, 0.8302499 , 0.8460003 ],\n",
       "        [0.8683934 , 0.00941936, 0.8484743 , 0.84481674, 0.8600445 ],\n",
       "        [0.874919  , 0.00914693, 0.8583889 , 0.8508079 , 0.87220395],\n",
       "        [0.88525116, 0.01153238, 0.8564776 , 0.8622029 , 0.8700761 ],\n",
       "        [0.89860433, 0.01029138, 0.8777402 , 0.87588865, 0.8906864 ],\n",
       "        [0.9016255 , 0.00787141, 0.88783395, 0.87929535, 0.90023154],\n",
       "        [0.9029547 , 0.00827593, 0.8884909 , 0.8786493 , 0.8987116 ],\n",
       "        [0.89818144, 0.00793401, 0.8937469 , 0.88182104, 0.90339303],\n",
       "        [0.89787936, 0.00683415, 0.88771445, 0.87706333, 0.8971917 ],\n",
       "        [0.9019881 , 0.00820484, 0.89159673, 0.88569766, 0.9056425 ],\n",
       "        [0.8991483 , 0.00755829, 0.8917759 , 0.87917787, 0.90248114],\n",
       "        [0.9216252 , 0.01348461, 0.8945234 , 0.8993834 , 0.90995914],\n",
       "        [0.90488833, 0.01682248, 0.87899446, 0.8804114 , 0.88983524],\n",
       "        [0.8998129 , 0.01005011, 0.88956606, 0.8790017 , 0.8982861 ],\n",
       "        [0.9062176 , 0.00931357, 0.88759506, 0.88998556, 0.9034538 ],\n",
       "        [0.9150997 , 0.00734494, 0.8979277 , 0.892335  , 0.91056716],\n",
       "        [0.91189724, 0.00813763, 0.90503514, 0.8950369 , 0.9155525 ],\n",
       "        [0.91516477, 0.00881403, 0.90688664, 0.89368594, 0.9120262 ],\n",
       "        [0.9100819 , 0.00741358, 0.90401983, 0.88998556, 0.91263425],\n",
       "        [0.9123208 , 0.00765166, 0.8967929 , 0.88916314, 0.9120262 ],\n",
       "        [0.8948333 , 0.00878338, 0.89571786, 0.8815274 , 0.8985901 ],\n",
       "        [0.8945308 , 0.00552438, 0.8893869 , 0.8774158 , 0.8975564 ],\n",
       "        [0.907359  , 0.00857393, 0.8862213 , 0.88311327, 0.89634055],\n",
       "        [0.9074195 , 0.00797975, 0.89780825, 0.89180636, 0.908196  ],\n",
       "        [0.9134705 , 0.00798425, 0.89524007, 0.88951564, 0.90764886],\n",
       "        [0.92853755, 0.01196595, 0.90157104, 0.91013235, 0.91768044],\n",
       "        [0.95504093, 0.01857105, 0.9177569 , 0.9316888 , 0.9302047 ],\n",
       "        [0.9712577 , 0.01580589, 0.941289  , 0.945492  , 0.95136213],\n",
       "        [0.97410166, 0.01582775, 0.96535873, 0.9729809 , 0.9785386 ],\n",
       "        [0.9764616 , 0.01294079, 0.962014  , 0.95007354, 0.9667438 ],\n",
       "        [0.9796686 , 0.0093596 , 0.9598042 , 0.95207053, 0.9702701 ],\n",
       "        [0.9486269 , 0.01036965, 0.9527565 , 0.942144  , 0.9503286 ],\n",
       "        [0.96938187, 0.01195803, 0.9515619 , 0.9464906 , 0.9651023 ],\n",
       "        [1.        , 0.02345143, 0.95526505, 0.9719237 , 0.9719724 ],\n",
       "        [0.996793  , 0.02048772, 1.        , 1.        , 1.        ],\n",
       "        [0.9906814 , 0.01842439, 0.94779927, 0.9641704 , 0.95908344],\n",
       "        [0.97906345, 0.01589113, 0.9793347 , 0.9686344 , 0.9707565 ]],\n",
       "       dtype=float32),\n",
       " 'x train': array([[[0.00187634, 0.04099471, 0.0023164 , 0.00229114, 0.00225276],\n",
       "         [0.00177645, 0.05843991, 0.0022364 , 0.00227803, 0.00213062],\n",
       "         [0.00175425, 0.0575933 , 0.00215641, 0.00212069, 0.00207634],\n",
       "         ...,\n",
       "         [0.00169281, 0.02050414, 0.00206309, 0.00205514, 0.0020492 ],\n",
       "         [0.00174289, 0.01783455, 0.00200977, 0.00204203, 0.0020492 ],\n",
       "         [0.00173733, 0.01631187, 0.00206309, 0.00204203, 0.0020492 ]],\n",
       " \n",
       "        [[0.03591988, 0.04990293, 0.04148833, 0.04095007, 0.04188177],\n",
       "         [0.03657764, 0.07415417, 0.0412729 , 0.04161086, 0.04183834],\n",
       "         [0.03689447, 0.08831859, 0.04196188, 0.04200734, 0.04215101],\n",
       "         ...,\n",
       "         [0.04508584, 0.09948291, 0.05271902, 0.05199473, 0.05245616],\n",
       "         [0.04779653, 0.13236846, 0.05490757, 0.05430226, 0.05522895],\n",
       "         [0.04913984, 0.10690693, 0.05478812, 0.0556658 , 0.055331  ]],\n",
       " \n",
       "        [[0.02553476, 0.4544776 , 0.02875383, 0.0290768 , 0.02709064],\n",
       "         [0.02489183, 0.27027267, 0.0295644 , 0.02922364, 0.02836522],\n",
       "         [0.0238561 , 0.20948726, 0.0293511 , 0.02888591, 0.0278441 ],\n",
       "         ...,\n",
       "         [0.02747283, 0.13912924, 0.03091038, 0.03110323, 0.03088397],\n",
       "         [0.02709484, 0.14080018, 0.03143938, 0.03142628, 0.03137034],\n",
       "         [0.02785821, 0.14168942, 0.03107249, 0.03193603, 0.03162004]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.00151501, 0.03009448, 0.00183645, 0.00185847, 0.00187278],\n",
       "         [0.00151501, 0.02004538, 0.00183645, 0.00183881, 0.00184564],\n",
       "         [0.00158014, 0.01882452, 0.00186312, 0.00189781, 0.00189992],\n",
       "         ...,\n",
       "         [0.00146544, 0.02512048, 0.00180979, 0.00179292, 0.00179135],\n",
       "         [0.00143279, 0.04498779, 0.00175646, 0.00172737, 0.00173706],\n",
       "         [0.00146544, 0.02127529, 0.00171647, 0.00175359, 0.00175064]],\n",
       " \n",
       "        [[0.00481061, 0.03859373, 0.00538937, 0.00551643, 0.00529263],\n",
       "         [0.00451532, 0.02744148, 0.00536271, 0.00536566, 0.00524513],\n",
       "         [0.00461954, 0.04353452, 0.00533604, 0.00547054, 0.00531298],\n",
       "         ...,\n",
       "         [0.00555174, 0.0402394 , 0.00638592, 0.0064342 , 0.00645972],\n",
       "         [0.00518118, 0.04788752, 0.00624927, 0.00625064, 0.00597117],\n",
       "         [0.00551121, 0.02930145, 0.0060093 , 0.00627031, 0.00602545]],\n",
       " \n",
       "        [[0.00149867, 0.16532873, 0.00160314, 0.00167492, 0.00161493],\n",
       "         [0.00157394, 0.10464856, 0.00177646, 0.00176014, 0.00173028],\n",
       "         [0.00155078, 0.06997471, 0.00173647, 0.0017667 , 0.00170314],\n",
       "         ...,\n",
       "         [0.00188615, 0.07327512, 0.00204336, 0.00212594, 0.00207905],\n",
       "         [0.0018213 , 0.07877805, 0.0020583 , 0.00206825, 0.00203563],\n",
       "         [0.00185465, 0.08260513, 0.00202523, 0.0021679 , 0.00203563]]],\n",
       "       dtype=float32),\n",
       " 'x test': array([[[2.40512922e-01, 3.52973714e-02, 2.54436195e-01, 2.51132160e-01,\n",
       "          2.51144022e-01],\n",
       "         [2.39815637e-01, 1.96805540e-02, 2.48806983e-01, 2.44817927e-01,\n",
       "          2.49107301e-01],\n",
       "         [2.36474335e-01, 1.81587879e-02, 2.47074917e-01, 2.43951559e-01,\n",
       "          2.44745106e-01],\n",
       "         ...,\n",
       "         [2.68332720e-01, 1.36278756e-02, 2.76281089e-01, 2.74715066e-01,\n",
       "          2.79414773e-01],\n",
       "         [2.70286918e-01, 9.35922377e-03, 2.74593830e-01, 2.73143888e-01,\n",
       "          2.79065192e-01],\n",
       "         [2.69718170e-01, 1.22548100e-02, 2.77863830e-01, 2.74582922e-01,\n",
       "          2.77712464e-01]],\n",
       " \n",
       "        [[5.12705301e-04, 4.24992815e-02, 6.99920929e-04, 6.88327535e-04,\n",
       "          6.41223451e-04],\n",
       "         [5.41774265e-04, 2.25067213e-02, 6.43258565e-04, 6.91605092e-04,\n",
       "          6.51400886e-04],\n",
       "         [5.73491212e-04, 2.73811147e-02, 6.89922774e-04, 7.17825314e-04,\n",
       "          7.05686805e-04],\n",
       "         ...,\n",
       "         [6.60702819e-04, 1.14721805e-02, 8.83233093e-04, 8.75158294e-04,\n",
       "          8.48177529e-04],\n",
       "         [6.36919052e-04, 1.71645060e-02, 8.29903351e-04, 8.16156913e-04,\n",
       "          7.90499151e-04],\n",
       "         [6.21062994e-04, 1.64522100e-02, 7.99908827e-04, 8.09601916e-04,\n",
       "          7.97290180e-04]],\n",
       " \n",
       "        [[1.56236347e-03, 1.26876101e-01, 1.73313275e-03, 1.76342088e-03,\n",
       "          1.65564532e-03],\n",
       "         [1.49867067e-03, 3.07212055e-01, 1.82312250e-03, 1.87486853e-03,\n",
       "          1.69974752e-03],\n",
       "         [1.46393257e-03, 1.13273062e-01, 1.63647765e-03, 1.66181172e-03,\n",
       "          1.62849925e-03],\n",
       "         ...,\n",
       "         [1.39734556e-03, 1.06646605e-01, 1.48316019e-03, 1.56348001e-03,\n",
       "          1.50636339e-03],\n",
       "         [1.39155495e-03, 4.81629334e-02, 1.58981350e-03, 1.57659012e-03,\n",
       "          1.56064949e-03],\n",
       "         [1.52762479e-03, 1.55060053e-01, 1.64314313e-03, 1.70770299e-03,\n",
       "          1.65564532e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[6.60708902e-05, 6.80302409e-03, 8.33242084e-05, 8.19440393e-05,\n",
       "          8.48183408e-05],\n",
       "         [8.98546132e-05, 7.59077445e-03, 1.09986046e-04, 1.11441754e-04,\n",
       "          1.15350784e-04],\n",
       "         [1.18928459e-04, 8.86747334e-03, 1.46652063e-04, 1.47500439e-04,\n",
       "          1.52674285e-04],\n",
       "         ...,\n",
       "         [7.13561021e-05, 4.30999044e-03, 8.66569171e-05, 8.84990877e-05,\n",
       "          9.16033241e-05],\n",
       "         [7.13561021e-05, 6.94789737e-03, 8.66569171e-05, 8.84990877e-05,\n",
       "          9.16033241e-05],\n",
       "         [6.87135034e-05, 5.83116338e-03, 8.66569171e-05, 8.52215380e-05,\n",
       "          8.82108507e-05]],\n",
       " \n",
       "        [[3.11850599e-04, 3.32967862e-02, 3.76622309e-04, 3.83494102e-04,\n",
       "          3.79983336e-04],\n",
       "         [3.25068657e-04, 3.02816052e-02, 3.89953231e-04, 3.99887620e-04,\n",
       "          3.83375824e-04],\n",
       "         [3.17135971e-04, 2.21958458e-02, 4.06622887e-04, 4.09720175e-04,\n",
       "          4.07123269e-04],\n",
       "         ...,\n",
       "         [4.06995008e-04, 3.47545780e-02, 5.09943464e-04, 5.01496834e-04,\n",
       "          5.08910220e-04],\n",
       "         [4.12280526e-04, 1.26100415e-02, 5.09943464e-04, 5.21161943e-04,\n",
       "          5.19087655e-04],\n",
       "         [4.46634745e-04, 2.01223437e-02, 5.16608881e-04, 5.60492277e-04,\n",
       "          5.29265148e-04]],\n",
       " \n",
       "        [[8.09651799e-04, 1.39471041e-02, 9.23225773e-04, 9.21043626e-04,\n",
       "          9.16033518e-04],\n",
       "         [8.21231515e-04, 9.68238711e-03, 9.09894938e-04, 9.14488628e-04,\n",
       "          9.29603470e-04],\n",
       "         [7.98072375e-04, 1.45009439e-02, 9.09894938e-04, 9.01378517e-04,\n",
       "          9.09248483e-04],\n",
       "         ...,\n",
       "         [9.97828436e-04, 5.15599176e-02, 1.11653609e-03, 1.10459689e-03,\n",
       "          1.11281010e-03],\n",
       "         [9.54405579e-04, 2.52789389e-02, 1.11653609e-03, 1.10459689e-03,\n",
       "          1.08567020e-03],\n",
       "         [9.19661834e-04, 2.87966505e-02, 1.06987788e-03, 1.05215656e-03,\n",
       "          1.01781427e-03]]], dtype=float32),\n",
       " 'y train': array([0.00174846, 0.04994768, 0.02813058, ..., 0.00153075, 0.0052217 ,\n",
       "        0.00181203]),\n",
       " 'y test': array([2.72736901e-01, 6.13130729e-04, 1.61158065e-03, ...,\n",
       "        6.34281796e-05, 4.57205434e-04, 9.13872188e-04]),\n",
       " 'test df': DatetimeIndex(['2018-06-29', '1983-04-05', '1998-12-22', '2003-06-05',\n",
       "                '1981-06-05', '2008-04-11', '1988-08-30', '2016-04-15',\n",
       "                '2008-06-11', '1995-11-16',\n",
       "                ...\n",
       "                '2018-01-30', '1984-02-09', '2010-12-21', '2012-01-17',\n",
       "                '1983-01-27', '2020-08-10', '1989-09-05', '1982-05-26',\n",
       "                '1986-05-05', '1996-10-22'],\n",
       "               dtype='datetime64[ns]', length=2057, freq=None)}"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data('AAPL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_LSTM_model(window_seq_length, num_features, num_layers=4, units=45, dropout=0.2):\n",
    "    rnn = Sequential()\n",
    "    for layer in range(num_layers):\n",
    "        if layer == 0:\n",
    "            rnn.add(LSTM(units, return_sequences=True, input_shape=(window_seq_length, num_features)))\n",
    "        elif layer == num_layers -1:\n",
    "            rnn.add(LSTM(units))\n",
    "        else:\n",
    "            rnn.add(LSTM(units, return_sequences=True))\n",
    "        rnn.add(Dropout(dropout))\n",
    "    rnn.add(Dense(units=1))\n",
    "    rnn.compile(optimizer='adam', metrics='mean_absolute_error', loss='huber_loss')\n",
    "    return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Epoch 1/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 0.0048 - mean_absolute_error: 0.0392\n",
      "Epoch 00001: val_loss improved from inf to 0.00015, saving model to model_checkpoint/2021-12-03_AMZN.h5\n",
      "77/77 [==============================] - 67s 781ms/step - loss: 0.0048 - mean_absolute_error: 0.0392 - val_loss: 1.4674e-04 - val_mean_absolute_error: 0.0083\n",
      "Epoch 2/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.3711e-04 - mean_absolute_error: 0.0122\n",
      "Epoch 00002: val_loss did not improve from 0.00015\n",
      "77/77 [==============================] - 39s 510ms/step - loss: 3.3711e-04 - mean_absolute_error: 0.0122 - val_loss: 2.1652e-04 - val_mean_absolute_error: 0.0089\n",
      "Epoch 3/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.8822e-04 - mean_absolute_error: 0.0131\n",
      "Epoch 00003: val_loss improved from 0.00015 to 0.00014, saving model to model_checkpoint/2021-12-03_AMZN.h5\n",
      "77/77 [==============================] - 39s 513ms/step - loss: 3.8822e-04 - mean_absolute_error: 0.0131 - val_loss: 1.3842e-04 - val_mean_absolute_error: 0.0078\n",
      "Epoch 4/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.8638e-04 - mean_absolute_error: 0.0111\n",
      "Epoch 00004: val_loss improved from 0.00014 to 0.00012, saving model to model_checkpoint/2021-12-03_AMZN.h5\n",
      "77/77 [==============================] - 40s 515ms/step - loss: 2.8638e-04 - mean_absolute_error: 0.0111 - val_loss: 1.1870e-04 - val_mean_absolute_error: 0.0072\n",
      "Epoch 5/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.0259e-04 - mean_absolute_error: 0.0116\n",
      "Epoch 00005: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 39s 512ms/step - loss: 3.0259e-04 - mean_absolute_error: 0.0116 - val_loss: 1.6147e-04 - val_mean_absolute_error: 0.0094\n",
      "Epoch 6/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.5756e-04 - mean_absolute_error: 0.0126\n",
      "Epoch 00006: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 40s 520ms/step - loss: 3.5756e-04 - mean_absolute_error: 0.0126 - val_loss: 1.4405e-04 - val_mean_absolute_error: 0.0079\n",
      "Epoch 7/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 2.6888e-04 - mean_absolute_error: 0.0109\n",
      "Epoch 00007: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 40s 523ms/step - loss: 2.6888e-04 - mean_absolute_error: 0.0109 - val_loss: 1.5533e-04 - val_mean_absolute_error: 0.0074\n",
      "Epoch 8/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.4026e-04 - mean_absolute_error: 0.0123\n",
      "Epoch 00008: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 39s 501ms/step - loss: 3.4026e-04 - mean_absolute_error: 0.0123 - val_loss: 7.7150e-04 - val_mean_absolute_error: 0.0196\n",
      "Epoch 9/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.5872e-04 - mean_absolute_error: 0.0127\n",
      "Epoch 00009: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 45s 590ms/step - loss: 3.5872e-04 - mean_absolute_error: 0.0127 - val_loss: 1.9674e-04 - val_mean_absolute_error: 0.0097\n",
      "Epoch 10/10\n",
      "77/77 [==============================] - ETA: 0s - loss: 3.9275e-04 - mean_absolute_error: 0.0132\n",
      "Epoch 00010: val_loss did not improve from 0.00012\n",
      "77/77 [==============================] - 38s 498ms/step - loss: 3.9275e-04 - mean_absolute_error: 0.0132 - val_loss: 1.5576e-04 - val_mean_absolute_error: 0.0074\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AMZN'\n",
    "window = 50\n",
    "predict = 7\n",
    "layers = 4\n",
    "units = 256\n",
    "dropout = 0.2\n",
    "date = time.strftime(\"%Y-%m-%d\")\n",
    "eps = 10\n",
    "b_size=64\n",
    "\n",
    "ticker_filename = os.path.join('data', f'{date}_{ticker}.csv')\n",
    "model_name = f'{date}_{ticker}'\n",
    "\n",
    "data = get_data(ticker, window, predict)\n",
    "data['original df'].to_csv(ticker_filename)\n",
    "\n",
    "model = make_LSTM_model(window, len(features), layers, units, dropout)\n",
    "m_checkpoint = ModelCheckpoint(filepath=os.path.join('model_checkpoint', model_name + '.h5'), \n",
    "                                save_best_only=True, save_weights_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join('tensorboard', model_name))\n",
    "\n",
    "model_history = model.fit(data['x train'], data['y train'], batch_size=b_size, epochs=eps, validation_data=(data['x test'], data['y test']), \n",
    "                            callbacks=[m_checkpoint, tensorboard], verbose=1)\n",
    "                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('tensorboard')\n",
    "os.mkdir('model_checkpoint')\n",
    "os.mkdir('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(m, d):\n",
    "    last_values = d['last values'][-predict:]\n",
    "    last_values = np.expand_dims(last_values, 0)\n",
    "    prediction = m.predict(last_values)\n",
    "    predicted_price = d['scalers']['adjclose'].inverse_transform(prediction)[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_finished_df(m, d):\n",
    "    x_test = d['x test']\n",
    "    y_test = d['y test']\n",
    "\n",
    "    y_prediction = m.predict(x_test)\n",
    "    y_test = np.squeeze(d['scalers']['adjclose'].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "    y_prediction = np.squeeze(d['scalers']['adjclose'].inverse_transform(y_prediction))\n",
    "    \n",
    "    test_df = d['test df']\n",
    "\n",
    "    test_df[f'actual adjclose {predict}'] = y_test\n",
    "    test_df[f'adjclose {predict}'] = y_prediction\n",
    "    test_df.sort_index(inplace=True)\n",
    "    finished_df = test_df\n",
    "    \n",
    "    return finished_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df):\n",
    "    plt.plot(df[f'actual adjclose {predict}'], c='b')\n",
    "    plt.plot(df[f'adjclose {predict}'], c='r')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Price')\n",
    "    plt.legend(['Actual Price', 'Predicted Price'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('model_checkpoint', model_name) + '.h5' \n",
    "model.load_weights(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 4s 99ms/step - loss: 1.1870e-04 - mean_absolute_error: 0.0072\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(data['x test'], data['y test'], verbose=1)\n",
    "mean_abs_error = data['scalers']['adjclose'].inverse_transform([[mae]])[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexes.datetimes.DatetimeIndex'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data['test df']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_16\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/729045505.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfinished_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_finished_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfuture_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Future price after {predict} days is {future_price:.2f}$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Mean absolute error: {mean_abs_error}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/2819445633.py\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(m, d)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjclose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_16\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "finished_df = get_finished_df(model, data)\n",
    "future_price = make_prediction(model, data)\n",
    "print(f'Future price after {predict} days is {future_price:.2f}$')\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Mean absolute error: {mean_abs_error}')\n",
    "plot(finished_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_result_folder = 'csv_results'\n",
    "if not os.path.isdir(csv_result_folder):\n",
    "    os.mkdir(csv_result_folder)\n",
    "csv_filename = os.path.join(csv_result_folder, model_name + '.csv')\n",
    "finished_df.to_csv(csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Epoch 1/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 0.0015 - mean_absolute_error: 0.0200\n",
      "Epoch 00001: val_loss improved from inf to 0.00007, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 78s 543ms/step - loss: 0.0015 - mean_absolute_error: 0.0200 - val_loss: 6.7249e-05 - val_mean_absolute_error: 0.0048\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.5471e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 00002: val_loss did not improve from 0.00007\n",
      "129/129 [==============================] - 67s 516ms/step - loss: 1.5471e-04 - mean_absolute_error: 0.0077 - val_loss: 1.2943e-04 - val_mean_absolute_error: 0.0072\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.0889e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00003: val_loss improved from 0.00007 to 0.00006, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 2.0889e-04 - mean_absolute_error: 0.0087 - val_loss: 6.1161e-05 - val_mean_absolute_error: 0.0053\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.0581e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00004: val_loss did not improve from 0.00006\n",
      "129/129 [==============================] - 65s 505ms/step - loss: 2.0581e-04 - mean_absolute_error: 0.0087 - val_loss: 3.0843e-04 - val_mean_absolute_error: 0.0105\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.6927e-04 - mean_absolute_error: 0.0098\n",
      "Epoch 00005: val_loss improved from 0.00006 to 0.00005, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 2.6927e-04 - mean_absolute_error: 0.0098 - val_loss: 4.8927e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.2243e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00006: val_loss did not improve from 0.00005\n",
      "129/129 [==============================] - 66s 511ms/step - loss: 2.2243e-04 - mean_absolute_error: 0.0096 - val_loss: 5.3081e-05 - val_mean_absolute_error: 0.0055\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3444e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 00007: val_loss did not improve from 0.00005\n",
      "129/129 [==============================] - 74s 578ms/step - loss: 1.3444e-04 - mean_absolute_error: 0.0080 - val_loss: 8.6670e-05 - val_mean_absolute_error: 0.0056\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3401e-04 - mean_absolute_error: 0.0078\n",
      "Epoch 00008: val_loss improved from 0.00005 to 0.00005, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 1.3401e-04 - mean_absolute_error: 0.0078 - val_loss: 4.5844e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2277e-04 - mean_absolute_error: 0.0076\n",
      "Epoch 00009: val_loss improved from 0.00005 to 0.00005, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 65s 507ms/step - loss: 1.2277e-04 - mean_absolute_error: 0.0076 - val_loss: 4.5529e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3731e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 00010: val_loss did not improve from 0.00005\n",
      "129/129 [==============================] - 66s 509ms/step - loss: 1.3731e-04 - mean_absolute_error: 0.0080 - val_loss: 5.2243e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2901e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 00011: val_loss did not improve from 0.00005\n",
      "129/129 [==============================] - 66s 514ms/step - loss: 1.2901e-04 - mean_absolute_error: 0.0077 - val_loss: 1.8058e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 2.0607e-04 - mean_absolute_error: 0.0099\n",
      "Epoch 00012: val_loss improved from 0.00005 to 0.00004, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 66s 513ms/step - loss: 2.0607e-04 - mean_absolute_error: 0.0099 - val_loss: 4.3641e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.7955e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00013: val_loss improved from 0.00004 to 0.00004, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 1.7955e-04 - mean_absolute_error: 0.0095 - val_loss: 4.0783e-05 - val_mean_absolute_error: 0.0034\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.6546e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00014: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 62s 481ms/step - loss: 1.6546e-04 - mean_absolute_error: 0.0093 - val_loss: 4.9147e-04 - val_mean_absolute_error: 0.0181\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.5486e-04 - mean_absolute_error: 0.0093\n",
      "Epoch 00015: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 63s 489ms/step - loss: 1.5486e-04 - mean_absolute_error: 0.0093 - val_loss: 1.0456e-04 - val_mean_absolute_error: 0.0124\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2725e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00016: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 69s 534ms/step - loss: 1.2725e-04 - mean_absolute_error: 0.0085 - val_loss: 1.1726e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4442e-04 - mean_absolute_error: 0.0095\n",
      "Epoch 00017: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 66s 513ms/step - loss: 1.4442e-04 - mean_absolute_error: 0.0095 - val_loss: 1.0983e-04 - val_mean_absolute_error: 0.0068\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1973e-04 - mean_absolute_error: 0.0085\n",
      "Epoch 00018: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 72s 559ms/step - loss: 1.1973e-04 - mean_absolute_error: 0.0085 - val_loss: 5.3415e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2165e-04 - mean_absolute_error: 0.0079\n",
      "Epoch 00019: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 70s 541ms/step - loss: 1.2165e-04 - mean_absolute_error: 0.0079 - val_loss: 1.3164e-04 - val_mean_absolute_error: 0.0107\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4084e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00020: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 71s 547ms/step - loss: 1.4084e-04 - mean_absolute_error: 0.0087 - val_loss: 1.4086e-04 - val_mean_absolute_error: 0.0106\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1476e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 00021: val_loss did not improve from 0.00004\n",
      "129/129 [==============================] - 81s 631ms/step - loss: 1.1476e-04 - mean_absolute_error: 0.0080 - val_loss: 7.4785e-05 - val_mean_absolute_error: 0.0051\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.5822e-04 - mean_absolute_error: 0.0094\n",
      "Epoch 00022: val_loss improved from 0.00004 to 0.00003, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 76s 590ms/step - loss: 1.5822e-04 - mean_absolute_error: 0.0094 - val_loss: 3.4668e-05 - val_mean_absolute_error: 0.0039\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3482e-04 - mean_absolute_error: 0.0088\n",
      "Epoch 00023: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 68s 524ms/step - loss: 1.3482e-04 - mean_absolute_error: 0.0088 - val_loss: 4.0398e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2838e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00024: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 538ms/step - loss: 1.2838e-04 - mean_absolute_error: 0.0081 - val_loss: 4.5327e-05 - val_mean_absolute_error: 0.0064\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2011e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00025: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 72s 557ms/step - loss: 1.2011e-04 - mean_absolute_error: 0.0082 - val_loss: 5.0899e-05 - val_mean_absolute_error: 0.0074\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3481e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00026: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 532ms/step - loss: 1.3481e-04 - mean_absolute_error: 0.0084 - val_loss: 3.5777e-05 - val_mean_absolute_error: 0.0043\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4223e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00027: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 71s 553ms/step - loss: 1.4223e-04 - mean_absolute_error: 0.0087 - val_loss: 3.3844e-05 - val_mean_absolute_error: 0.0036\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3099e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00028: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 68s 528ms/step - loss: 1.3099e-04 - mean_absolute_error: 0.0084 - val_loss: 3.7329e-05 - val_mean_absolute_error: 0.0032\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4723e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00029: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 534ms/step - loss: 1.4723e-04 - mean_absolute_error: 0.0092 - val_loss: 3.7263e-05 - val_mean_absolute_error: 0.0046\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1148e-04 - mean_absolute_error: 0.0077\n",
      "Epoch 00030: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 536ms/step - loss: 1.1148e-04 - mean_absolute_error: 0.0077 - val_loss: 7.7684e-05 - val_mean_absolute_error: 0.0038\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3171e-04 - mean_absolute_error: 0.0086\n",
      "Epoch 00031: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 65s 505ms/step - loss: 1.3171e-04 - mean_absolute_error: 0.0086 - val_loss: 1.7896e-04 - val_mean_absolute_error: 0.0100\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.7890e-04 - mean_absolute_error: 0.0101\n",
      "Epoch 00032: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 67s 517ms/step - loss: 1.7890e-04 - mean_absolute_error: 0.0101 - val_loss: 4.5024e-05 - val_mean_absolute_error: 0.0062\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4684e-04 - mean_absolute_error: 0.0096\n",
      "Epoch 00033: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 70s 543ms/step - loss: 1.4684e-04 - mean_absolute_error: 0.0096 - val_loss: 1.1797e-04 - val_mean_absolute_error: 0.0084\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1064e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00034: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 81s 626ms/step - loss: 1.1064e-04 - mean_absolute_error: 0.0081 - val_loss: 5.7120e-05 - val_mean_absolute_error: 0.0045\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2083e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00035: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 535ms/step - loss: 1.2083e-04 - mean_absolute_error: 0.0083 - val_loss: 1.7084e-04 - val_mean_absolute_error: 0.0096\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4640e-04 - mean_absolute_error: 0.0090\n",
      "Epoch 00036: val_loss improved from 0.00003 to 0.00003, saving model to model_checkpoint/2021-12-03_AAPL.h5\n",
      "129/129 [==============================] - 84s 655ms/step - loss: 1.4640e-04 - mean_absolute_error: 0.0090 - val_loss: 3.2125e-05 - val_mean_absolute_error: 0.0037\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.0599e-04 - mean_absolute_error: 0.0081\n",
      "Epoch 00037: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 529ms/step - loss: 1.0599e-04 - mean_absolute_error: 0.0081 - val_loss: 3.4450e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1726e-04 - mean_absolute_error: 0.0078\n",
      "Epoch 00038: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 65s 507ms/step - loss: 1.1726e-04 - mean_absolute_error: 0.0078 - val_loss: 4.8523e-05 - val_mean_absolute_error: 0.0042\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.2904e-04 - mean_absolute_error: 0.0084\n",
      "Epoch 00039: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 71s 550ms/step - loss: 1.2904e-04 - mean_absolute_error: 0.0084 - val_loss: 4.3904e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.4855e-04 - mean_absolute_error: 0.0092\n",
      "Epoch 00040: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 75s 583ms/step - loss: 1.4855e-04 - mean_absolute_error: 0.0092 - val_loss: 8.4247e-05 - val_mean_absolute_error: 0.0054\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1820e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00041: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 78s 604ms/step - loss: 1.1820e-04 - mean_absolute_error: 0.0083 - val_loss: 3.6361e-05 - val_mean_absolute_error: 0.0040\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1249e-04 - mean_absolute_error: 0.0082\n",
      "Epoch 00042: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 66s 512ms/step - loss: 1.1249e-04 - mean_absolute_error: 0.0082 - val_loss: 4.7552e-05 - val_mean_absolute_error: 0.0059\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.3090e-04 - mean_absolute_error: 0.0087\n",
      "Epoch 00043: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 70s 540ms/step - loss: 1.3090e-04 - mean_absolute_error: 0.0087 - val_loss: 5.5479e-05 - val_mean_absolute_error: 0.0078\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1836e-04 - mean_absolute_error: 0.0083\n",
      "Epoch 00044: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 69s 530ms/step - loss: 1.1836e-04 - mean_absolute_error: 0.0083 - val_loss: 4.1030e-05 - val_mean_absolute_error: 0.0063\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 9.8576e-05 - mean_absolute_error: 0.0075\n",
      "Epoch 00045: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 73s 569ms/step - loss: 9.8576e-05 - mean_absolute_error: 0.0075 - val_loss: 3.7750e-05 - val_mean_absolute_error: 0.0058\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1014e-04 - mean_absolute_error: 0.0079\n",
      "Epoch 00046: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 64s 498ms/step - loss: 1.1014e-04 - mean_absolute_error: 0.0079 - val_loss: 3.9639e-05 - val_mean_absolute_error: 0.0061\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1536e-04 - mean_absolute_error: 0.0080\n",
      "Epoch 00047: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 66s 511ms/step - loss: 1.1536e-04 - mean_absolute_error: 0.0080 - val_loss: 1.0419e-04 - val_mean_absolute_error: 0.0077\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.0022e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 00048: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 65s 507ms/step - loss: 1.0022e-04 - mean_absolute_error: 0.0074 - val_loss: 4.4470e-05 - val_mean_absolute_error: 0.0050\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.1602e-04 - mean_absolute_error: 0.0078\n",
      "Epoch 00049: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 67s 523ms/step - loss: 1.1602e-04 - mean_absolute_error: 0.0078 - val_loss: 4.1308e-05 - val_mean_absolute_error: 0.0031\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - ETA: 0s - loss: 1.0081e-04 - mean_absolute_error: 0.0074\n",
      "Epoch 00050: val_loss did not improve from 0.00003\n",
      "129/129 [==============================] - 68s 527ms/step - loss: 1.0081e-04 - mean_absolute_error: 0.0074 - val_loss: 3.4740e-05 - val_mean_absolute_error: 0.0042\n"
     ]
    }
   ],
   "source": [
    "ticker = 'AAPL'\n",
    "window = 50\n",
    "predict = 7\n",
    "layers = 4\n",
    "units = 256\n",
    "dropout = 0.2\n",
    "date = time.strftime(\"%Y-%m-%d\")\n",
    "eps = 10\n",
    "b_size=64\n",
    "\n",
    "ticker_filename = os.path.join('data', f'{date}_{ticker}.csv')\n",
    "model_name = f'{date}_{ticker}'\n",
    "\n",
    "data = get_data(ticker, window, predict)\n",
    "data['original df'].to_csv(ticker_filename)\n",
    "\n",
    "model = make_LSTM_model(window, len(features), layers, units, dropout)\n",
    "m_checkpoint = ModelCheckpoint(filepath=os.path.join('model_checkpoint', model_name + '.h5'), \n",
    "                                save_best_only=True, save_weights_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join('tensorboard', model_name))\n",
    "\n",
    "model_history = model.fit(data['x train'], data['y train'], batch_size=b_size, epochs=eps, validation_data=(data['x test'], data['y test']), \n",
    "                            callbacks=[m_checkpoint, tensorboard], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - 5s 76ms/step - loss: 3.2125e-05 - mean_absolute_error: 0.0037\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/2206641436.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_abs_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjclose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinished_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_finished_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfuture_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Future price after {predict} days is {future_price:.2f}$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/2819445633.py\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(m, d)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjclose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('model_checkpoint', model_name) + '.h5' \n",
    "model.load_weights(model_path)\n",
    "loss, mae = model.evaluate(data['x test'], data['y test'], verbose=1)\n",
    "mean_abs_error = data['scalers']['adjclose'].inverse_transform([[mae]])[0][0]\n",
    "finished_df = get_finished_df(model, data)\n",
    "future_price = make_prediction(model, data)\n",
    "print(f'Future price after {predict} days is {future_price:.2f}$')\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Mean absolute error: {mean_abs_error}')\n",
    "plot(finished_df)\n",
    "\n",
    "csv_result_folder = 'csv_results'\n",
    "if not os.path.isdir(csv_result_folder):\n",
    "    os.mkdir(csv_result_folder)\n",
    "csv_filename = os.path.join(csv_result_folder, model_name + '.csv')\n",
    "finished_df.to_csv(csv_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Epoch 1/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.0040 - mean_absolute_error: 0.0441\n",
      "Epoch 00001: val_loss improved from inf to 0.00050, saving model to model_checkpoint/2021-12-03_BLK.h5\n",
      "70/70 [==============================] - 52s 587ms/step - loss: 0.0040 - mean_absolute_error: 0.0441 - val_loss: 5.0194e-04 - val_mean_absolute_error: 0.0225\n",
      "Epoch 2/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.8548e-04 - mean_absolute_error: 0.0172\n",
      "Epoch 00002: val_loss improved from 0.00050 to 0.00022, saving model to model_checkpoint/2021-12-03_BLK.h5\n",
      "70/70 [==============================] - 39s 559ms/step - loss: 3.8548e-04 - mean_absolute_error: 0.0172 - val_loss: 2.2256e-04 - val_mean_absolute_error: 0.0134\n",
      "Epoch 3/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.9000e-04 - mean_absolute_error: 0.0187\n",
      "Epoch 00003: val_loss did not improve from 0.00022\n",
      "70/70 [==============================] - 35s 507ms/step - loss: 4.9000e-04 - mean_absolute_error: 0.0187 - val_loss: 5.5442e-04 - val_mean_absolute_error: 0.0207\n",
      "Epoch 4/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3531e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 00004: val_loss did not improve from 0.00022\n",
      "70/70 [==============================] - 37s 522ms/step - loss: 4.3531e-04 - mean_absolute_error: 0.0185 - val_loss: 9.5850e-04 - val_mean_absolute_error: 0.0294\n",
      "Epoch 5/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3526e-04 - mean_absolute_error: 0.0183\n",
      "Epoch 00005: val_loss improved from 0.00022 to 0.00019, saving model to model_checkpoint/2021-12-03_BLK.h5\n",
      "70/70 [==============================] - 41s 583ms/step - loss: 4.3526e-04 - mean_absolute_error: 0.0183 - val_loss: 1.8998e-04 - val_mean_absolute_error: 0.0133\n",
      "Epoch 6/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.3696e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00006: val_loss did not improve from 0.00019\n",
      "70/70 [==============================] - 45s 634ms/step - loss: 3.3696e-04 - mean_absolute_error: 0.0160 - val_loss: 1.9972e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 7/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 4.3174e-04 - mean_absolute_error: 0.0185\n",
      "Epoch 00007: val_loss improved from 0.00019 to 0.00018, saving model to model_checkpoint/2021-12-03_BLK.h5\n",
      "70/70 [==============================] - 36s 508ms/step - loss: 4.3174e-04 - mean_absolute_error: 0.0185 - val_loss: 1.7786e-04 - val_mean_absolute_error: 0.0116\n",
      "Epoch 8/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.1488e-04 - mean_absolute_error: 0.0154\n",
      "Epoch 00008: val_loss did not improve from 0.00018\n",
      "70/70 [==============================] - 39s 561ms/step - loss: 3.1488e-04 - mean_absolute_error: 0.0154 - val_loss: 2.1212e-04 - val_mean_absolute_error: 0.0131\n",
      "Epoch 9/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.3074e-04 - mean_absolute_error: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.00018\n",
      "70/70 [==============================] - 37s 521ms/step - loss: 3.3074e-04 - mean_absolute_error: 0.0160 - val_loss: 7.3992e-04 - val_mean_absolute_error: 0.0243\n",
      "Epoch 10/10\n",
      "70/70 [==============================] - ETA: 0s - loss: 3.4509e-04 - mean_absolute_error: 0.0165\n",
      "Epoch 00010: val_loss did not improve from 0.00018\n",
      "70/70 [==============================] - 36s 520ms/step - loss: 3.4509e-04 - mean_absolute_error: 0.0165 - val_loss: 1.8815e-04 - val_mean_absolute_error: 0.0109\n"
     ]
    }
   ],
   "source": [
    "ticker = 'BLK'\n",
    "window = 50\n",
    "predict = 7\n",
    "layers = 4\n",
    "units = 256\n",
    "dropout = 0.2\n",
    "date = time.strftime(\"%Y-%m-%d\")\n",
    "eps = 10\n",
    "b_size=64\n",
    "\n",
    "ticker_filename = os.path.join('data', f'{date}_{ticker}.csv')\n",
    "model_name = f'{date}_{ticker}'\n",
    "\n",
    "data = get_data(ticker, window, predict)\n",
    "data['original df'].to_csv(ticker_filename)\n",
    "\n",
    "model = make_LSTM_model(window, len(features), layers, units, dropout)\n",
    "m_checkpoint = ModelCheckpoint(filepath=os.path.join('model_checkpoint', model_name + '.h5'), \n",
    "                                save_best_only=True, save_weights_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join('tensorboard', model_name))\n",
    "\n",
    "model_history = model.fit(data['x train'], data['y train'], batch_size=b_size, epochs=eps, validation_data=(data['x test'], data['y test']), \n",
    "                            callbacks=[m_checkpoint, tensorboard], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/35 [==============================] - 3s 72ms/step - loss: 1.7786e-04 - mean_absolute_error: 0.0116\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_17\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/1048028326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmean_abs_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjclose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmae\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinished_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_finished_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfuture_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Future price after {predict} days is {future_price:.2f}$'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Loss: {loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/p2/5m2z5r2j4hv7c1rt_bsbww6h0000gn/T/ipykernel_10275/2819445633.py\u001b[0m in \u001b[0;36mmake_prediction\u001b[0;34m(m, d)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'last values'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mlast_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpredicted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scalers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adjclose'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredicted_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_17\" is incompatible with the layer: expected shape=(None, 50, 5), found shape=(None, 7, 5)\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join('model_checkpoint', model_name) + '.h5' \n",
    "model.load_weights(model_path)\n",
    "loss, mae = model.evaluate(data['x test'], data['y test'], verbose=1)\n",
    "mean_abs_error = data['scalers']['adjclose'].inverse_transform([[mae]])[0][0]\n",
    "finished_df = get_finished_df(model, data)\n",
    "future_price = make_prediction(model, data)\n",
    "print(f'Future price after {predict} days is {future_price:.2f}$')\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Mean absolute error: {mean_abs_error}')\n",
    "plot(finished_df)\n",
    "\n",
    "csv_result_folder = 'csv_results'\n",
    "if not os.path.isdir(csv_result_folder):\n",
    "    os.mkdir(csv_result_folder)\n",
    "csv_filename = os.path.join(csv_result_folder, model_name + '.csv')\n",
    "finished_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
